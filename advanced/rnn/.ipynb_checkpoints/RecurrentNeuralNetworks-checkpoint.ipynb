{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Weights in RNNs\n",
    "\n",
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Look at the code in [Part A: Single Unit Simple Recurrent Layer](#Part-A:-Single-Unit-Simple-Recurrent-Layer) and complete the [Part A Exercise](#Part-A-Exercise)\n",
    "0. Look at the code in [Part B: Two Unit Simple Recurrent Layer](#Part-B:-Two-Unit-Simple-Recurrent-Layer) and complete the [Part B Exercise](#Part-B-Exercise)\n",
    "0. Optionally, look at the code in [Part C: LSTM Layer](#Part-C:-LSTM-Layer) and complete the [Part C Exercise](#Part-C-Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation/Sources\n",
    "* [Class Notes](https://jennselby.github.io/MachineLearningCourseNotes/#recurrent-neural-networks)\n",
    "* [https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/) for information on sequence classification with keras\n",
    "* [https://keras.io/](https://keras.io/) Keras API documentation\n",
    "* [Keras recurrent tutorial](https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Single Unit Simple Recurrent Layer\n",
    "\n",
    "Before we dive into something as complicated as LSTMs, Let's take a deeper look at simple recurrent layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons in the recurrent layer pass their output to the next layer, but also back to themselves. The input shape says that we'll be passing in one-dimensional inputs of unspecified length (the None is what makes it unspecified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_SRNN = Sequential()\n",
    "one_unit_SRNN.add(SimpleRNN(units=1, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.34557903]], dtype=float32), array([[1.]], dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights = one_unit_SRNN.get_weights()\n",
    "one_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the weights to whatever we want, to test out what happens with different weight values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.]], dtype=float32), array([[1.]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights[0][0][0] = 1\n",
    "one_unit_SRNN_weights[1][0][0] = 1\n",
    "one_unit_SRNN.set_weights(one_unit_SRNN_weights)\n",
    "one_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then pass in different input values, to see what the model outputs.\n",
    "\n",
    "The code below passes in a single sample that has three time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN.predict(numpy.array([ [[3], [3], [7]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A Exercise\n",
    "Figure out what the two weights in the one_unit_SRNN model control. Be sure to test your hypothesis thoroughly. Use different weights and different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Two Unit Simple Recurrent Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_unit_SRNN = Sequential()\n",
    "two_unit_SRNN.add(SimpleRNN(units=2, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.21958375, -1.2462564 ]], dtype=float32),\n",
       " array([[-0.8535344 ,  0.52103645],\n",
       "        [ 0.52103645,  0.8535344 ]], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights = two_unit_SRNN.get_weights()\n",
    "two_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.]], dtype=float32), array([[0., 1.],\n",
       "        [0., 1.]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights[0][0][0] = 1\n",
    "two_unit_SRNN_weights[0][0][1] = 1\n",
    "two_unit_SRNN_weights[1][0][0] = 0\n",
    "two_unit_SRNN_weights[1][0][1] = 1\n",
    "two_unit_SRNN_weights[1][1][0] = 0\n",
    "two_unit_SRNN_weights[1][1][1] = 1\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "two_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This passes in a single sample with four time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN.predict(numpy.array([ [[3], [3], [7], [5]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B Exercise\n",
    "What do each of the six weights of the two_unit_SRNN control? Again, test out your hypotheses carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: LSTM Layer\n",
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_LSTM = Sequential()\n",
    "one_unit_LSTM.add(LSTM(units=1, input_shape=(None, 1),\n",
    "                       activation='linear', recurrent_activation='linear',\n",
    "                       use_bias=False, unit_forget_bias=False,\n",
    "                       kernel_initializer='zeros',\n",
    "                       recurrent_initializer='zeros',\n",
    "                       return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights = one_unit_LSTM.get_weights()\n",
    "one_unit_LSTM_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 1., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights[0][0][0] = 1\n",
    "one_unit_LSTM_weights[0][0][1] = 0\n",
    "one_unit_LSTM_weights[0][0][2] = 1\n",
    "one_unit_LSTM_weights[0][0][3] = 1\n",
    "one_unit_LSTM_weights[1][0][0] = 0\n",
    "one_unit_LSTM_weights[1][0][1] = 0\n",
    "one_unit_LSTM_weights[1][0][2] = 0\n",
    "one_unit_LSTM_weights[1][0][3] = 0\n",
    "one_unit_LSTM.set_weights(one_unit_LSTM_weights)\n",
    "one_unit_LSTM.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.],\n",
       "        [ 1.],\n",
       "        [ 8.],\n",
       "        [64.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM.predict(numpy.array([ [[0], [1], [2], [4]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C Exercise\n",
    "### Optional\n",
    "Conceptually, the [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) has several _gates_:\n",
    "\n",
    "* __Forget gate__: these weights allow some long-term memories to be forgotten.\n",
    "* __Input gate__: these weights decide what new information will be added to the context cell.\n",
    "* __Output gate__: these weights decide what pieces of the new information and updated context will be passed on to the output.\n",
    "\n",
    "It also has a __cell__ that can hold onto information from the current input (as well as things it has remembered from previous inputs), so that it can be used in later outputs.\n",
    "\n",
    "Identify which weights in the one_unit_LSTM model are connected with the context and which are associated with the three gates. This is considerably more difficult to do by looking at the inputs and outputs, so you could also treat this as a code reading exercise and look through the keras code to find the answer.\n",
    "\n",
    "_Note_: The output from the predict call is what the linked explanation calls $h_{t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
