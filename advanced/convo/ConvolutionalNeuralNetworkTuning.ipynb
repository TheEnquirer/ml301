{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [MNIST Data](#MNIST-Data)\n",
    "    * [Convolutional Neural Network Model](#Convolutional-Neural-Network-Model)\n",
    "    * [Train Model](#Train-Model)\n",
    "    * [Validation](#Validation)\n",
    "0. Complete the [Exercise](#Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# allow matplotlib graphics to display in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# import numpy, for image dimension manipulation\n",
    "import numpy\n",
    "\n",
    "# import validation methods from scikit-learn\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# import the dataset and neural network layers from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database) is a famous dataset of images of handwritten numbers. The goal is to be able to figure out which number is in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants to describe the MNIST images\n",
    "NUM_ROWS = 28 \n",
    "NUM_COLUMNS = 28\n",
    "NUM_COLORS = 1\n",
    "IMG_SHAPE = (NUM_ROWS, NUM_COLUMNS, NUM_COLORS)\n",
    "\n",
    "# constant to describe the MNIST output labels\n",
    "# there are ten different numbers, 0-9\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "((images_train, labels_train), (images_test, labels_test)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one particular image and its label, to better understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13ef18f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(images_train[17], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(Conv2D(filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=8, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 1.4788\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 1.5431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1424f3910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras requires a color dimension, so we need to expand each image to have one\n",
    "images_3d_train = numpy.expand_dims(images_train, axis=3)\n",
    "\n",
    "# the labels need to be one-hot encoded, to match the ten outputs of our model\n",
    "labels_onehot_train = to_categorical(labels_train)\n",
    "\n",
    "# set up the model to be ready for training\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(images_3d_train, labels_onehot_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras requires a color dimension, so we need to expand each image to have one\n",
    "images_3d_test = numpy.expand_dims(images_test, axis=3)\n",
    "\n",
    "# get the predictions from the model\n",
    "predictions_test_onehot = model.predict(images_3d_test)\n",
    "\n",
    "# get the index that has the highest probability\n",
    "predictions_test = numpy.argmax(predictions_test_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2851"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the overall accuracy\n",
    "accuracy_score(y_true=labels_test, y_pred=predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.7628866 , 0.23838682, 0.05263158, 0.45023697, 0.11111111,\n",
       "        0.        , 0.31504065, 0.84537389, 0.03627907, 0.        ]),\n",
       " array([0.0755102 , 0.99471366, 0.03488372, 0.28217822, 0.00101833,\n",
       "        0.        , 0.64718163, 0.64883268, 0.04004107, 0.        ]),\n",
       " array([0.13741876, 0.38460228, 0.04195804, 0.34692635, 0.00201816,\n",
       "        0.        , 0.42378674, 0.73417722, 0.03806735, 0.        ]),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get precision, recall, f-score, and number of examples of each digit\n",
    "# can you see which digits are easiest for the model, and which are hardest?\n",
    "precision_recall_fscore_support(y_true=labels_test, y_pred=predictions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Can you get the model to perform better? Try adding more layers, or taking them away. \n",
    "Take a look at the documentation for the [convolutional](https://keras.io/layers/convolutional/) and [dense](https://keras.io/layers/core/) layers and the [sequential model](https://keras.io/models/sequential/) to understand the options that you have and try out different things.\n",
    "\n",
    "It might also be a good idea to find examples posted online of networks that did well with MNIST and try out some of the configuration they used. Make sure you cite any sources you use!\n",
    "\n",
    "Take notes of what performance you get from different configurations.\n",
    "\n",
    "Comment on what patterns you observed in terms of what changes helped your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
