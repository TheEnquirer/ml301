{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [First Model](#First-Model)\n",
    "    * [Create Images](#Create-Images)\n",
    "    * [Run Images Through Model](#Run-Images-Through-Model)\n",
    "0. Answer the [Model 1 Questions](#Model-1-Questions)\n",
    "0. Read through the code for the [Second Model](#Second-Model)\n",
    "0. Complete [Exercise #1](#Exercise-#1)\n",
    "0. Optionally, complete [Exercise #2](#Exercise-#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1,\n",
    "                  input_shape=(image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.27241194]],\n",
       " \n",
       "         [[ 0.46208835]],\n",
       " \n",
       "         [[ 0.27045178]]],\n",
       " \n",
       " \n",
       "        [[[-0.06313407]],\n",
       " \n",
       "         [[ 0.4143771 ]],\n",
       " \n",
       "         [[-0.39599395]]],\n",
       " \n",
       " \n",
       "        [[[-0.25146186]],\n",
       " \n",
       "         [[ 0.3285122 ]],\n",
       " \n",
       "         [[-0.04878753]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13e393dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13e47b940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0, image1]: # You may find it easier to take one of these out, to look at them one at a time\n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]]],\n",
       "\n",
       "\n",
       "       [[[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.]],\n",
       "\n",
       "        [[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Questions\n",
    "\n",
    "### Answer these before going on to the second model!\n",
    "\n",
    "1. There are a lot of numbers in the output above: 2 arrays of 7 arrays of 7 arrays of a single element. Why are they in groups of seven?\n",
    "\n",
    "2. When we created the model, we asked it to have one filter. In which image do we get the highest absolute values in the filter outputs? How does this relate to the pattern of weights that was set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. First dimension has two items for two images, second dimension has 7 items for each y position (with overlaps), third dimension has 7 items for each x position, and the fourth dimension has the value that the filter returns. We can tell it goes y then x because the x values returned by the prediction for the first image are different. \n",
    "\n",
    "\n",
    "2. The second image. Because the lines are horizontal, they match the patterns in the filter. As the filter moves across the x axis, we get repeated values. This means that each set of filter outputs will only have one value, instead of the mixed values we see in image one. Thus, we get an optimal set of values in image two. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to understand the manual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.4378244 , -0.31234333]],\n",
       " \n",
       "         [[ 0.18990043,  0.01763976]],\n",
       " \n",
       "         [[-0.23176485,  0.39664087]]],\n",
       " \n",
       " \n",
       "        [[[-0.16228268,  0.0864208 ]],\n",
       " \n",
       "         [[-0.07747737, -0.17069474]],\n",
       " \n",
       "         [[ 0.4668955 , -0.22340785]]],\n",
       " \n",
       " \n",
       "        [[[ 0.39172307,  0.39734456]],\n",
       " \n",
       "         [[-0.35964906, -0.04957616]],\n",
       " \n",
       "         [[-0.04198083, -0.17273206]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 0.2652571 ],\n",
       "          [-0.31467378]],\n",
       " \n",
       "         [[-0.16132903],\n",
       "          [ 0.3008578 ]],\n",
       " \n",
       "         [[ 0.46140304],\n",
       "          [-0.01365176]]],\n",
       " \n",
       " \n",
       "        [[[ 0.43120316],\n",
       "          [-0.35708025]],\n",
       " \n",
       "         [[ 0.46998748],\n",
       "          [ 0.35759017]],\n",
       " \n",
       "         [[-0.21747527],\n",
       "          [-0.33765593]]],\n",
       " \n",
       " \n",
       "        [[[-0.13338712],\n",
       "          [ 0.33573553]],\n",
       " \n",
       "         [[ 0.08350828],\n",
       "          [ 0.228843  ]],\n",
       " \n",
       "         [[-0.21285215],\n",
       "          [-0.23080896]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 1 is for setting the biases of the first layer.\n",
    "# They are zero by default, so leave them that way and\n",
    "# move on to layer 2, which contains the weights for the\n",
    "# filters of the second layer.\n",
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(images, model):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image0, image1], model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13eb96f40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [225, 0, 225, 0, 225, 0, 225, 0, 225] ,\n",
    "    [0, 225, 0, 225, 0, 225, 0, 225, 0] ,\n",
    "    [225, 0, 225, 0, 225, 0, 225, 0, 225] ,\n",
    "    [0, 225, 0, 225, 0, 225, 0, 225, 0] ,\n",
    "    [225, 0, 225, 0, 225, 0, 225, 0, 225] ,\n",
    "    [0, 225, 0, 225, 0, 225, 0, 225, 0] ,\n",
    "    [225, 0, 225, 0, 225, 0, 225, 0, 225] ,\n",
    "    [0, 225, 0, 225, 0, 225, 0, 225, 0] ,\n",
    "    [225, 0, 225, 0, 225, 0, 225, 0, 225]\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255) # not generated by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13ebf7d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 0, 0, 0, 0, 0, 0, 0, 255],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [0, 0, 255, 0, 0, 0, 255, 0, 0],\n",
    "    [0, 0, 0, 255, 0, 255, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 255, 0, 255, 0, 0, 0],\n",
    "    [0, 0, 255, 0, 0, 0, 255, 0, 0],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [255, 0, 0, 0, 0, 0, 0, 0, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2925.]]],\n",
       "\n",
       "\n",
       "       [[[3825.]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white], model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #2\n",
    "\n",
    "### Optional\n",
    "\n",
    "Add additional filters to the model or create a new model with your own filters. Create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = image_white.tolist()\n",
    "g = 0\n",
    "for i,v in enumerate(arr):\n",
    "#     g = 0\n",
    "    for j,n in enumerate(v):\n",
    "        arr[i][j] = g\n",
    "        g += 3\n",
    "#         g += 28\n",
    "\n",
    "# flip comments for r-l gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13ec6e7f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_1 = numpy.array(arr, dtype=numpy.uint8)\n",
    "imshow(image_1, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(arr):\n",
    "    for j,n in enumerate(v):\n",
    "        arr[i][j] = g\n",
    "        g -= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13ecb2c70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_2 = numpy.array(arr, dtype=numpy.uint8)\n",
    "imshow(image_2, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab with Nick (ish)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model2.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-1., -1.]],\n",
       " \n",
       "         [[ 0., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.]],\n",
       " \n",
       "         [[ 1.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[ 0.,  1.]],\n",
       " \n",
       "         [[ 1.,  1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[0.   ],\n",
       "          [0.   ]],\n",
       " \n",
       "         [[0.125],\n",
       "          [0.125]],\n",
       " \n",
       "         [[0.25 ],\n",
       "          [0.25 ]]],\n",
       " \n",
       " \n",
       "        [[[0.375],\n",
       "          [0.375]],\n",
       " \n",
       "         [[0.5  ],\n",
       "          [0.5  ]],\n",
       " \n",
       "         [[0.625],\n",
       "          [0.625]]],\n",
       " \n",
       " \n",
       "        [[[0.75 ],\n",
       "          [0.75 ]],\n",
       " \n",
       "         [[0.875],\n",
       "          [0.875]],\n",
       " \n",
       "         [[1.   ],\n",
       "          [1.   ]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    g = -1\n",
    "    for x in range(kernel_size):\n",
    "        weights2[layer_num][y][x][0][filter_num] = g\n",
    "        g += 1\n",
    "        \n",
    "        \n",
    "filter_num = 1\n",
    "g = -1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights2[layer_num][y][x][0][filter_num] = g\n",
    "    g += 1\n",
    "\n",
    "    \n",
    "layer_num = 2\n",
    "filter_num = 0\n",
    "g = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        weights2[layer_num][y][x][input_filter_num][filter_num] = g\n",
    "            \n",
    "        input_filter_num = 1\n",
    "        weights2[layer_num][y][x][input_filter_num][filter_num] = g\n",
    "        g += 0.125\n",
    "    \n",
    "# tried to detect gradients.. couldn't figure out how to do relative weights\n",
    "# ie. make it multiply based off of its neighbouring pixels, like with a gradient\n",
    "# decided to weight the lower right higher\n",
    "# but this is fundamentally flawed as pure white will get a higher score, \n",
    "# or a correct pattern will get a relatively low score\n",
    "    \n",
    "weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -1.7368078]]],\n",
       "\n",
       "\n",
       "       [[[-32.447853 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should work better on image_1\n",
    "predict_images([image_1, image_2], model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
