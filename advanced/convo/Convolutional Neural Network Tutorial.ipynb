{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [First Model](#First-Model)\n",
    "    * [Create Images](#Create-Images)\n",
    "    * [Run Images Through Model](#Run-Images-Through-Model)\n",
    "0. Answer the [Model 1 Questions](#Model-1-Questions)\n",
    "0. Read through the code for the [Second Model](#Second-Model)\n",
    "0. Complete [Exercise #1](#Exercise-#1)\n",
    "0. Optionally, complete [Exercise #2](#Exercise-#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1,\n",
    "                  input_shape=(image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.10406637]],\n",
       " \n",
       "         [[ 0.5136833 ]],\n",
       " \n",
       "         [[ 0.38653535]]],\n",
       " \n",
       " \n",
       "        [[[-0.19607425]],\n",
       " \n",
       "         [[ 0.42464244]],\n",
       " \n",
       "         [[-0.4395233 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.47101247]],\n",
       " \n",
       "         [[ 0.16527855]],\n",
       " \n",
       "         [[-0.45755833]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13873ab10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1388ac110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0, image1]: # You may find it easier to take one of these out, to look at them one at a time\n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]]],\n",
       "\n",
       "\n",
       "       [[[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.]],\n",
       "\n",
       "        [[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Questions\n",
    "\n",
    "### Answer these before going on to the second model!\n",
    "\n",
    "1. There are a lot of numbers in the output above: 2 arrays of 7 arrays of 7 arrays of a single element. Why are they in groups of seven?\n",
    "\n",
    "2. When we created the model, we asked it to have one filter. In which image do we get the highest absolute values in the filter outputs? How does this relate to the pattern of weights that was set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to understand the manual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.18620053, -0.0254904 ]],\n",
       " \n",
       "         [[-0.34455183,  0.07090899]],\n",
       " \n",
       "         [[ 0.31497756, -0.04884526]]],\n",
       " \n",
       " \n",
       "        [[[ 0.34851035,  0.44877866]],\n",
       " \n",
       "         [[-0.11065054,  0.39561316]],\n",
       " \n",
       "         [[-0.01922548, -0.08240607]]],\n",
       " \n",
       " \n",
       "        [[[-0.3907231 , -0.23695081]],\n",
       " \n",
       "         [[-0.30338448,  0.34737644]],\n",
       " \n",
       "         [[ 0.44047478,  0.09450045]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[-0.33926663],\n",
       "          [-0.37579873]],\n",
       " \n",
       "         [[-0.447349  ],\n",
       "          [ 0.15102217]],\n",
       " \n",
       "         [[-0.19185525],\n",
       "          [-0.3894932 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.13201055],\n",
       "          [ 0.20396301]],\n",
       " \n",
       "         [[-0.12954187],\n",
       "          [-0.18424916]],\n",
       " \n",
       "         [[-0.13625324],\n",
       "          [ 0.21633765]]],\n",
       " \n",
       " \n",
       "        [[[-0.32364768],\n",
       "          [-0.24014083]],\n",
       " \n",
       "         [[ 0.25038263],\n",
       "          [ 0.156149  ]],\n",
       " \n",
       "         [[ 0.09394589],\n",
       "          [-0.27343506]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 1 is for setting the biases of the first layer.\n",
    "# They are zero by default, so leave them that way and\n",
    "# move on to layer 2, which contains the weights for the\n",
    "# filters of the second layer.\n",
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model1.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image0, image1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x138962710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1390262d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.]]],\n",
       "\n",
       "\n",
       "       [[[-2295.]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #2\n",
    "\n",
    "### Optional\n",
    "\n",
    "Add additional filters to the model or create a new model with your own filters. Create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
