{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [First Model](#First-Model)\n",
    "    * [Create Images](#Create-Images)\n",
    "    * [Run Images Through Model](#Run-Images-Through-Model)\n",
    "0. Answer the [Model 1 Questions](#Model-1-Questions)\n",
    "0. Read through the code for the [Second Model](#Second-Model)\n",
    "0. Complete [Exercise #1](#Exercise-#1)\n",
    "0. Optionally, complete [Exercise #2](#Exercise-#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1,\n",
    "                  input_shape=(image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13939d3a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13b47f460>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0, image1]: # You may find it easier to take one of these out, to look at them one at a time\n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]]],\n",
       "\n",
       "\n",
       "       [[[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.]],\n",
       "\n",
       "        [[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Questions\n",
    "\n",
    "### Answer these before going on to the second model!\n",
    "\n",
    "1. There are a lot of numbers in the output above: 2 arrays of 7 arrays of 7 arrays of a single element. Why are they in groups of seven?\n",
    "\n",
    "2. When we created the model, we asked it to have one filter. In which image do we get the highest absolute values in the filter outputs? How does this relate to the pattern of weights that was set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. First dimension has two items for two images, second dimension has 7 items for each y position (with overlaps), third dimension has 7 items for each x position, and the fourth dimension has the value that the filter returns. We can tell it goes y then x because the x values returned by the prediction for the first image are different. \n",
    "\n",
    "\n",
    "2. The second image. Because the lines are horizontal, they match the patterns in the filter. As the filter moves across the x axis, we get repeated values. This means that each set of filter outputs will only have one value, instead of the mixed values we see in image one. Thus, we get an optimal set of values in image two. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to understand the manual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.18620053, -0.0254904 ]],\n",
       " \n",
       "         [[-0.34455183,  0.07090899]],\n",
       " \n",
       "         [[ 0.31497756, -0.04884526]]],\n",
       " \n",
       " \n",
       "        [[[ 0.34851035,  0.44877866]],\n",
       " \n",
       "         [[-0.11065054,  0.39561316]],\n",
       " \n",
       "         [[-0.01922548, -0.08240607]]],\n",
       " \n",
       " \n",
       "        [[[-0.3907231 , -0.23695081]],\n",
       " \n",
       "         [[-0.30338448,  0.34737644]],\n",
       " \n",
       "         [[ 0.44047478,  0.09450045]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[-0.33926663],\n",
       "          [-0.37579873]],\n",
       " \n",
       "         [[-0.447349  ],\n",
       "          [ 0.15102217]],\n",
       " \n",
       "         [[-0.19185525],\n",
       "          [-0.3894932 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.13201055],\n",
       "          [ 0.20396301]],\n",
       " \n",
       "         [[-0.12954187],\n",
       "          [-0.18424916]],\n",
       " \n",
       "         [[-0.13625324],\n",
       "          [ 0.21633765]]],\n",
       " \n",
       " \n",
       "        [[[-0.32364768],\n",
       "          [-0.24014083]],\n",
       " \n",
       "         [[ 0.25038263],\n",
       "          [ 0.156149  ]],\n",
       " \n",
       "         [[ 0.09394589],\n",
       "          [-0.27343506]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 1 is for setting the biases of the first layer.\n",
    "# They are zero by default, so leave them that way and\n",
    "# move on to layer 2, which contains the weights for the\n",
    "# filters of the second layer.\n",
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model1.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image0, image1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x138962710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1390262d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.]]],\n",
       "\n",
       "\n",
       "       [[[-2295.]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #2\n",
    "\n",
    "### Optional\n",
    "\n",
    "Add additional filters to the model or create a new model with your own filters. Create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
